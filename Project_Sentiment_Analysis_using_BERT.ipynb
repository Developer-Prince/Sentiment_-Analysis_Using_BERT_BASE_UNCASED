{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Sentiment_Analysis_using_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10b0971736fe4e2d92387f469a0df98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b20204c416434a869bb8811469b59d0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29ba58ba9223467da7e576809a169c5f",
              "IPY_MODEL_da71612f87ed4d0bae8f7bcffb9d04ce"
            ]
          }
        },
        "b20204c416434a869bb8811469b59d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29ba58ba9223467da7e576809a169c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a9d31897b454d6a86a50829d90d47e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65a1f7ef7fe3420a910d1f7ea46f5322"
          }
        },
        "da71612f87ed4d0bae8f7bcffb9d04ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f41d9ed6e9b6479ca8e8c1c274aed90b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.47kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f7219f29dac4ce6beadf5d79a2f2460"
          }
        },
        "1a9d31897b454d6a86a50829d90d47e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65a1f7ef7fe3420a910d1f7ea46f5322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f41d9ed6e9b6479ca8e8c1c274aed90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f7219f29dac4ce6beadf5d79a2f2460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dab64bd24d6645159a793e11d6340ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_261adb5a7191403f970ac2e1d008697e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fd37e01588740cbbe0fd939f7ab2465",
              "IPY_MODEL_31f58ac109964791b41501c53fbd440b"
            ]
          }
        },
        "261adb5a7191403f970ac2e1d008697e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fd37e01588740cbbe0fd939f7ab2465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88b8c13ea2394c72ba8666b0b3aa6a17",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad7865e076b54593a3fed30384a771ba"
          }
        },
        "31f58ac109964791b41501c53fbd440b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81704ced4ac24e0ea9ed92744faf738a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 45.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e404e9dffaa4c1eab92a12ef2aea119"
          }
        },
        "88b8c13ea2394c72ba8666b0b3aa6a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad7865e076b54593a3fed30384a771ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81704ced4ac24e0ea9ed92744faf738a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e404e9dffaa4c1eab92a12ef2aea119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c910acecf6bc4731b63b297b6c1e0204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_160ae6952a2c40a68f5bf7ac3e2e2f0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3200a072b93c4f24a9478a2b62d6a19c",
              "IPY_MODEL_e12339097faa49b89bd4efe6ed8f1716"
            ]
          }
        },
        "160ae6952a2c40a68f5bf7ac3e2e2f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3200a072b93c4f24a9478a2b62d6a19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7dd6d9c77bcc4c2881699c2940d182cd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1677e2614e864a90a2d66e7cbc9dc7d4"
          }
        },
        "e12339097faa49b89bd4efe6ed8f1716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d88a5abf27c64a95b98b0e0a9ff148ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 115kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54802636d9fe467497ccb1ea9e80ff3d"
          }
        },
        "7dd6d9c77bcc4c2881699c2940d182cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1677e2614e864a90a2d66e7cbc9dc7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d88a5abf27c64a95b98b0e0a9ff148ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54802636d9fe467497ccb1ea9e80ff3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "772c48139b924aee9c154aba1eaa41f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e026dcd0dfe4295956a1aab224a6209",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0d315473158b43498ccb7c2cb8e37766",
              "IPY_MODEL_58768c1a5faf4fadade3e6dd21a78456"
            ]
          }
        },
        "9e026dcd0dfe4295956a1aab224a6209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d315473158b43498ccb7c2cb8e37766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_436670ce35dd45e3b069f1da605c077c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0df69d37e42c44f191e797aff9bad67d"
          }
        },
        "58768c1a5faf4fadade3e6dd21a78456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40e7ca82b83b4860972655cb8d016e87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:01&lt;00:00, 353kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d64b0fba6c7348d092ac11072491d77d"
          }
        },
        "436670ce35dd45e3b069f1da605c077c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0df69d37e42c44f191e797aff9bad67d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40e7ca82b83b4860972655cb8d016e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d64b0fba6c7348d092ac11072491d77d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa9540a358544ea78c775a58ed030032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1029d6c9449f4987860fb954f26d8604",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40a8ea3652cf4886935f1ae09e4f081d",
              "IPY_MODEL_02d4702936eb41d0a04f2770c4215870"
            ]
          }
        },
        "1029d6c9449f4987860fb954f26d8604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40a8ea3652cf4886935f1ae09e4f081d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8efd9ae0328b467e99520c4950121e58",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdaa1e495ecd45b39b8105b23cfc8af4"
          }
        },
        "02d4702936eb41d0a04f2770c4215870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83617c416c5a4e929bbd2efc1784f6a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 38.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a6bfe690e874d1bb8b5029d7bbd1e9e"
          }
        },
        "8efd9ae0328b467e99520c4950121e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdaa1e495ecd45b39b8105b23cfc8af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83617c416c5a4e929bbd2efc1784f6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a6bfe690e874d1bb8b5029d7bbd1e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c85823ef777f4a718f4cddc1a5a1b9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0ea21f709854dd79e0117b6e5ccf922",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d763853e36dd4792b44360d6d7a09a2c",
              "IPY_MODEL_7d59edeb6f91414a990953897c9d048f"
            ]
          }
        },
        "c0ea21f709854dd79e0117b6e5ccf922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d763853e36dd4792b44360d6d7a09a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9e5257d589748fbbc90e1cc4d81de2b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14640,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14640,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ed666f6ed6f4b34ab44da7f73e90147"
          }
        },
        "7d59edeb6f91414a990953897c9d048f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7e5dc5ea1ae42ebbf335590901eba13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14640/14640 [00:01&lt;00:00, 7628.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58df6e42c27541e4bfc873e01a8a0d93"
          }
        },
        "a9e5257d589748fbbc90e1cc4d81de2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ed666f6ed6f4b34ab44da7f73e90147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7e5dc5ea1ae42ebbf335590901eba13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58df6e42c27541e4bfc873e01a8a0d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPV6GD0oXtQk"
      },
      "source": [
        "# Objective\n",
        "\n",
        "In this notebook, we will fine-tune a pre-trained BERT model to perform sentiment analysis on a twitter data.\n",
        "\n",
        "# Table of Contents\n",
        "\n",
        "1. Setup\n",
        "  - Using Google Colab for training\n",
        "  - Installing the Hugging Face's Transformers Library\n",
        "2. Loading & Understanding BERT\n",
        "  - Download Pretrained BERT model\n",
        "  - Tokenization and Input Formatting\n",
        "  - Understanding Input and Output\n",
        "3. Preparing Data\n",
        "  - Loading and Reading Twitter Airline\n",
        "  - Text Cleaning\n",
        "  - Preparing Input and Output Data\n",
        "  - Training and Validation Data\n",
        "  - Define Dataloaders\n",
        "4. Model Finetuning\n",
        "  - Approach: Fine-Tuning Only Head\n",
        "  - Define Model Architecture\n",
        "  - Define Optimizer and Loss function\n",
        "  - Model Training and Evaluation\n",
        "  - Train the Model\n",
        "  - Model Evaluation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLnXNGquujFX"
      },
      "source": [
        "# 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5dWVBhsvBpB"
      },
      "source": [
        "## 1.1 Using Google Colab for training\n",
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we are going to train a large neural network, it's best to take advantage of the GPU/TPU (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QUIh1DwGdK"
      },
      "source": [
        "We will identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plFhDqWS7IDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f015990-0030-43e3-d128-97cd42cd4866"
      },
      "source": [
        "#import torch library\n",
        "import torch\n",
        "\n",
        "# check GPU availability\n",
        "if torch.cuda.is_available():    \n",
        "    # select GPU    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "device"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qksck1C7e3I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9df9779-06ac-4b08-f20f-3b151e3e2550"
      },
      "source": [
        "# check GPU name\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL4kE0e9xyl0"
      },
      "source": [
        "## 1.2. Installing the Hugging Face's Transformers Library\n",
        "\n",
        "Hugging Face 🤗 is the one of the most popular Natural Language Processing communities for deep learning researchers, hands-on practitioners and educators. It provides State of Art architectures for everyone.\n",
        "\n",
        "\n",
        "The Transformers library (formerly known as pytorch-transformers) provides a wide range of general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, etc) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with a wide range of pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jdjScBvG-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e8a559-86db-4662-e569-dcb2c4ffba74"
      },
      "source": [
        "#install hugging face transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.2MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 14.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 13.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 9.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 10.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 9.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 9.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 9.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 9.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 9.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 9.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 9.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 9.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 9.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 9.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 9.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 9.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 9.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eLFxRkQL1R"
      },
      "source": [
        "# 2. Loading & Understanding BERT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M1sab_G9bOl"
      },
      "source": [
        "##2.1 Download Pretrained BERT model\n",
        "\n",
        "We will use the uncased pre-trained version of the BERT base model. It was trained on lower-cased English text. \n",
        "\n",
        "You can find more pre-trained models here https://huggingface.co/transformers/pretrained_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZGp7pmiIa42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "10b0971736fe4e2d92387f469a0df98e",
            "b20204c416434a869bb8811469b59d0e",
            "29ba58ba9223467da7e576809a169c5f",
            "da71612f87ed4d0bae8f7bcffb9d04ce",
            "1a9d31897b454d6a86a50829d90d47e7",
            "65a1f7ef7fe3420a910d1f7ea46f5322",
            "f41d9ed6e9b6479ca8e8c1c274aed90b",
            "8f7219f29dac4ce6beadf5d79a2f2460",
            "dab64bd24d6645159a793e11d6340ab0",
            "261adb5a7191403f970ac2e1d008697e",
            "3fd37e01588740cbbe0fd939f7ab2465",
            "31f58ac109964791b41501c53fbd440b",
            "88b8c13ea2394c72ba8666b0b3aa6a17",
            "ad7865e076b54593a3fed30384a771ba",
            "81704ced4ac24e0ea9ed92744faf738a",
            "0e404e9dffaa4c1eab92a12ef2aea119"
          ]
        },
        "outputId": "4c9f2852-508b-44e0-83c8-dffc5aff937f"
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# download bert pretrained model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10b0971736fe4e2d92387f469a0df98e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dab64bd24d6645159a793e11d6340ab0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzkcvW6F5aE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cffe800-4b3d-46be-c5ef-90da000070ee"
      },
      "source": [
        "# print bert architecture\n",
        "print(bert)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYGt3oSZ4fzZ"
      },
      "source": [
        "##2.2 Tokenization and Input Formatting\n",
        "\n",
        "**Download BERT Tokenizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCZVXkA30cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "c910acecf6bc4731b63b297b6c1e0204",
            "160ae6952a2c40a68f5bf7ac3e2e2f0b",
            "3200a072b93c4f24a9478a2b62d6a19c",
            "e12339097faa49b89bd4efe6ed8f1716",
            "7dd6d9c77bcc4c2881699c2940d182cd",
            "1677e2614e864a90a2d66e7cbc9dc7d4",
            "d88a5abf27c64a95b98b0e0a9ff148ab",
            "54802636d9fe467497ccb1ea9e80ff3d",
            "772c48139b924aee9c154aba1eaa41f5",
            "9e026dcd0dfe4295956a1aab224a6209",
            "0d315473158b43498ccb7c2cb8e37766",
            "58768c1a5faf4fadade3e6dd21a78456",
            "436670ce35dd45e3b069f1da605c077c",
            "0df69d37e42c44f191e797aff9bad67d",
            "40e7ca82b83b4860972655cb8d016e87",
            "d64b0fba6c7348d092ac11072491d77d",
            "fa9540a358544ea78c775a58ed030032",
            "1029d6c9449f4987860fb954f26d8604",
            "40a8ea3652cf4886935f1ae09e4f081d",
            "02d4702936eb41d0a04f2770c4215870",
            "8efd9ae0328b467e99520c4950121e58",
            "cdaa1e495ecd45b39b8105b23cfc8af4",
            "83617c416c5a4e929bbd2efc1784f6a4",
            "8a6bfe690e874d1bb8b5029d7bbd1e9e"
          ]
        },
        "outputId": "78ff0e8a-6616-4809-8032-3352628378fb"
      },
      "source": [
        "#importing fast \"BERT\" tokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c910acecf6bc4731b63b297b6c1e0204",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "772c48139b924aee9c154aba1eaa41f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa9540a358544ea78c775a58ed030032",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosuQLl15olj"
      },
      "source": [
        "**Steps Followed for Input Formatting**\n",
        "\n",
        "1. Tokenization\n",
        "\n",
        "2. Special Tokens\n",
        "\n",
        "  * Prepend the `[CLS]` token to the start of the sequence.\n",
        "  * Append the `[SEP]` token to the end of the sequence.\n",
        "\n",
        "3. Pad sequences \n",
        "\n",
        "4. Converting tokens to integers\n",
        "\n",
        "5. Create Attention masks to avoid pad tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MBNXOU_BVj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9f489b-4786-4359-b91e-be65061f1ede"
      },
      "source": [
        "#input text\n",
        "text = \"Jim Henson was a puppeteer\"\n",
        "\n",
        "sent_id = tokenizer.encode(text, \n",
        "                           # add [CLS] and [SEP] tokens\n",
        "                           add_special_tokens=True,\n",
        "                           # specify maximum length for the sequences                                  \n",
        "                           max_length = 10,\n",
        "                           truncation = True,\n",
        "                           # add pad tokens to the right side of the sequence\n",
        "                           pad_to_max_length='right')\n",
        "                           \n",
        "# print integer sequence\n",
        "print(\"Integer Sequence: {}\".format(sent_id))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer Sequence: [101, 3958, 27227, 2001, 1037, 13997, 11510, 102, 0, 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH_fCLgKt9I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b67de16-97f3-41b5-d449-88bb75e1fc4a"
      },
      "source": [
        "# convert integers back to text\n",
        "print(\"Tokenized Text:\",tokenizer.convert_ids_to_tokens(sent_id))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized Text: ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQRb3ghOufP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9877416-c644-4f11-cc2f-4d8909a39e10"
      },
      "source": [
        "# decode the tokenized text\n",
        "decoded = tokenizer.decode(sent_id)\n",
        "print(\"Decoded String: {}\".format(decoded))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoded String: [CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4HGTu_RAOof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093f4b71-5b97-4847-8413-85dba3138f3a"
      },
      "source": [
        "# mask to avoid performing attention on padding token indices. \n",
        "# mask values: 1 for tokens that are NOT MASKED, 0 for MASKED tokens.   \n",
        "att_mask = [int(tok > 0) for tok in sent_id]\n",
        "\n",
        "print(\"Attention Mask:\",att_mask)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF2MqKaT69Iz"
      },
      "source": [
        "##2.3 Understanding Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IcDHx93CJnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675a9412-4f7a-4b8d-f268-470f7eb41055"
      },
      "source": [
        "# convert lists to tensors\n",
        "sent_id = torch.tensor(sent_id)\n",
        "att_mask = torch.tensor(att_mask)\n",
        "\n",
        "# reshaping tensor in form of (batch,text length)\n",
        "sent_id = sent_id.unsqueeze(0)\n",
        "att_mask = att_mask.unsqueeze(0)\n",
        "\n",
        "# reshaped tensor\n",
        "print(sent_id)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "picPPo9vfXE3",
        "outputId": "dc783abd-936b-4707-8189-845087b46b55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv3ebAJVBoMW"
      },
      "source": [
        "# pass integer sequence to bert model\n",
        "outputs = bert(sent_id, attention_mask=att_mask)  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLtc7RRzzc0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59816bc4-a341-487a-8063-a70cc0217e3d"
      },
      "source": [
        "## unpack the ouput of bert model\n",
        "\n",
        "# hidden states at each timestep\n",
        "all_hidden_states = outputs[0]\n",
        "# hidden states at first timestep ([CLS] token)\n",
        "cls_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of last hidden states:\",all_hidden_states.shape)\n",
        "print(\"Shape of CLS hidden state:\",cls_hidden_state.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of last hidden states: torch.Size([1, 10, 768])\n",
            "Shape of CLS hidden state: torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6xTpvKwfSlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694b53a8-1f75-4928-d207-71e6b98b04ba"
      },
      "source": [
        "cls_hidden_state"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
              "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
              "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
              "          0.3924,  0.6863, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
              "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
              "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
              "         -0.8711,  0.0508,  0.0505, -0.1635,  0.1716,  0.4363,  0.4330, -0.0333,\n",
              "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
              "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
              "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
              "         -0.0400,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
              "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
              "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
              "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
              "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
              "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
              "         -0.1696, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
              "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
              "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
              "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
              "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
              "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2164, -0.9851, -0.4444,  0.5759,\n",
              "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
              "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
              "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2186,  0.5282, -0.3149, -0.4375,\n",
              "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
              "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
              "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
              "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
              "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
              "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
              "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
              "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
              "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
              "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
              "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
              "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
              "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
              "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
              "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
              "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
              "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
              "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
              "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
              "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
              "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
              "          0.9268, -0.4224, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
              "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
              "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
              "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
              "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
              "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
              "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
              "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
              "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
              "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
              "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
              "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
              "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
              "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
              "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
              "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
              "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
              "         -0.9936, -0.1999, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
              "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
              "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
              "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
              "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
              "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1412,\n",
              "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
              "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
              "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
              "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
              "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
              "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
              "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
              "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
              "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0723,\n",
              "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
              "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
              "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
              "          0.3962, -0.5012, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
              "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
              "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
              "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
              "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
              "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
              "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
              "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
              "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
              "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
              "          0.1236, -0.3705, -0.3958, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
              "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
              "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
              "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
              "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
              "       grad_fn=<TanhBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQj1-E2pQY6H"
      },
      "source": [
        "#3. Preparing Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGQamTe3ebu"
      },
      "source": [
        "\n",
        "##3.1 Loading and Reading Twitter Airline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHLW3M3KJEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "3c58f806-da37-4da5-c6e6-7c1d8a2061f1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# increase the output column width\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# read CSV file\n",
        "# This is my path you have to put your path where you tweet file is stored\n",
        "df = pd.read_csv('/content/drive/MyDrive/Work Book/Airline_Tweets-200904-165552/Tweets.csv')\n",
        "\n",
        "# print first 5 rows\n",
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzLKBEuUKJAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f44824-c298-4b0f-d87f-385f488f2621"
      },
      "source": [
        "#shape of the dataframe\n",
        "df.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36CP54lLf2gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6023f94-1e69-4767-f221-5a1ce067baa6"
      },
      "source": [
        "df['text'].sample(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10325                                                                     @USAirways I intend to..very much. My 4,000 followers will as well.\n",
              "3029                               @united so funny that my boarding pass said PRIORITY a because clearly I am not a priority to this airline\n",
              "3011     @united gives Belfast a #Hug with the new unmissable #BusHug format #impact #busads #thinkbus @BelfastAirport http://t.co/AvbdstJUJS\n",
              "12868                                                             @AmericanAir just messaged you. Please have someone contact us immediately.\n",
              "282                            @VirginAmerica Is there anything going on with the website? I've been getting a lot of errors past 30 minutes.\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GirJa9_sWJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc48caa-45ab-496e-cac2-10b965aabf38"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWcEVUWIMGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a372b62f-9883-4589-d653-f91c98d63b65"
      },
      "source": [
        "# class distribution\n",
        "df['airline_sentiment'].value_counts(normalize = True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.626913\n",
              "neutral     0.211680\n",
              "positive    0.161407\n",
              "Name: airline_sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ArDZS9tVuPS"
      },
      "source": [
        "# saving the value counts to a list\n",
        "class_counts = df['airline_sentiment'].value_counts().tolist()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWWstFVe3x00"
      },
      "source": [
        "##3.2 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ol7s5sTGUgj"
      },
      "source": [
        "#library for pattern matching\n",
        "import re\n",
        "\n",
        "#define a function for text cleaning\n",
        "def preprocessor(text):\n",
        "  \n",
        "  #convering text to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  #remove user mentions\n",
        "  text = re.sub(r'@[A-Za-z0-9]+','',text)           \n",
        "  \n",
        "  #remove hashtags\n",
        "  #text = re.sub(r'#[A-Za-z0-9]+','',text)         \n",
        "  \n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "  \n",
        "  #split token to remove extra spaces\n",
        "  tokens = text.split()\n",
        "  \n",
        "  #join tokens by space\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLsz50lCnXC"
      },
      "source": [
        "# perform text cleaning\n",
        "df['clean_text']= df['text'].apply(preprocessor)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEnvlwJdz9-t"
      },
      "source": [
        "# save cleaned text and labels to a variable\n",
        "text   = df['clean_text'].values\n",
        "labels = df['airline_sentiment'].values"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7qq7aLst01a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcbd5b1-d071-4dc1-e147-2d3cb76dbc69"
      },
      "source": [
        "#cleaned text\n",
        "text[50:55]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['is flight 769 on it\\'s way? was supposed to take off 30 minutes ago. website still shows \"on time\" not \"in flight\". thanks.',\n",
              "       'julie andrews all the way though was very impressive! no to',\n",
              "       'wish you flew out of atlanta... soon?',\n",
              "       'julie andrews. hands down.',\n",
              "       'will flights be leaving dallas for la on february 24th?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbVmXPN_ao6"
      },
      "source": [
        "##3.3 Preparing Input and Output Data\n",
        "\n",
        "\n",
        "**Preparing Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzd8-2P0l3T"
      },
      "source": [
        "#importing label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#define label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a numbers\n",
        "labels = le.fit_transform(labels)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOF8XUDWuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3425dd-b2dc-4d37-dcb6-b254ef5230ff"
      },
      "source": [
        "#classes\n",
        "le.classes_"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBFVkRgoDX_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b70c367-028e-407e-c656-2e2dc4df2c3b"
      },
      "source": [
        "labels"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKh8Rcuw_vOt"
      },
      "source": [
        "**Preparing Input Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUFCQkM0-Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9c04ba8f-9219-4b9b-a298-aa38b6c421d4"
      },
      "source": [
        "# library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute no. of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "plt.hist(num, bins = 30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram: Length of sentences')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZc0lEQVR4nO3df5xcdX3v8debBMJPSSBriklgI43YYKvSbQzK9eaKQgA16b2CUJSA6SO1YotVK4HbNlTLvdCrIrYWGiVNsJSQUi1poaUpP0qtQNlQfoUfZQvBJM2PhRAQg9CUz/3jfLeeDLO7szOzM7P5vp+Pxzz2nO/3zDmfc7J5z5nvnDmriMDMzPKwT7sLMDOz1nHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKGfAUnrJc1tdx05krRC0u81aV3HSHpA0g8l/Xoz1mn5ceiPcZI2SHp/Rdu5kr43MB8Rx0bEncOsp1tSSBo/SqW2VOUx2Eu2+QXgjog4JCK+Porb+S/tOI42uhz61hJ7y4tJmx0FrG93ETa2OfQzUH43IGm2pF5JL0raJumrabG70s+dkl6SdLykfST9lqRnJG2XdK2kQ0vrPSf1PSfptyu2c4mkGyX9qaQXgXPTtu+WtFPSFkl/KGm/0vpC0qckPZmGML4k6WhJ30/1ri4v38DxeKuktZJ2SHpC0hmlvhWSviHp5lTDvZKOLvWflJ7zgqQ/kvQPkn5Z0s8AVwPHp+O3s7TJSYOtr0ptH07DcTsl3ZnWi6Tbgf8B/GFa/1uqPPdcSU+l7Twt6exS3yckPSbpeUm3Sjqq1BeSPpmO+860/xpsnyRNkPRlST9Iv0NXSzog9c2VtEnS59LvzBZJ55W2dYCkr6Tfmxckfa/03Dnp33qnpAdVGpIcat9shCLCjzH8ADYA769oOxf4XrVlgLuBj6fpg4E5abobCGB86XmfAPqAN6dlvwN8O/XNAl4CTgD2A74M/EdpO5ek+QUUJxcHAD8PzAHGp+09BnymtL0AbgLeABwLvALclrZ/KPAosLC0/E7ghEGOyx7HoNR+ELAROC/V8U7gWWBW6l8BPAfMTv3XAatS32TgReB/pr4L0j7+8mDbHGp9VWp7C/Aj4APAvhTDOX3Afqn/zoFtDbJfLwLHpPkjgGPT9Py0np9JNfwW8P2K4/7XwETgSKAfmDfEPl0BrAEOAw4B/gr4v6lvLrAb+GLah1OBXcCk1P+NtB9TgXHAu4EJaf65tPw+6Rg8B3QNtW9+1JEZ7S7Ajwb/AYtAfykF4MBjF4OH/l3A7wKTK9bTzetD/zbgU6X5Y1LIjQd+B7i+1Hcg8Cp7hv5dw9T+GeC7pfkA3lOaXwdcWJr/CvC1Go/L68IqtX8U+MeKtj8GlqbpFcC3Sn2nAo+n6XOAu0t9ongBGS70q66vSm2/Dawuze8DbAbmpvk7GTr0dwL/Czigou9vgEUV690FHFU67ieU+lcDS6rtU9rnHwFHl9qOB55O03OBlyt+j7ZTvNjvk/reXqX+C0knFKW2W4GFQ+2bHyN/eHhn77AgIiYOPIBPDbHsIoozyscl3Sfpg0Ms+ybgmdL8MxSBPyX1bRzoiIhdFGdmZRvLM5LeIumvJW1NQz7/h+LsuWxbafrlKvMHD1FvLY4C3pWGEHamIYuzgZ8qLbO1NL2rtM3KfQ5gUw3bHGx9lfY43hHxWtre1OE2EBE/onhB+ySwJQ0nvTV1HwVcWdrfHRThXV5vrTV2UbzAryut729T+4DnImJ3lfVNBvYH/q3Keo8CTq/4dzkBOGKYfbMRcuhnJiKejIizgDcClwM3SjqI4myv0r9T/GcccCTFW/dtwBZg2kBHGpc9vHJzFfNXAY8DMyPiDcDFFOHTShuBfyi/SEbEwRHxqzU8t3KfVZ6n+jEciT2Od1r/dIqz/WFFxK0R8QGK4Y/HgW+mro3Ar1Ts8wER8f1aVlsx/yzFi++xpXUdGhG1vBg/C/wYqPaZxkaKM/1yjQdFxGXD7JuNkEM/M5I+JqkrnUUOfNj4GsU47msU4+cDrgd+Q9IMSQdTnJnfkM7ibgQ+JOnd6cPVSxg+wA+hGJt9KZ2p1RK0jZCk/csPirHrt0j6uKR90+MXBj4wHcbNwM9KWqDiaqTz2fMdwjZgmur/sHk1cJqkEyXtC3yO4nONYcNZ0hRJ89ML+CsUQ36vpe6rgYskHZuWPVTS6TXWtMc+pd+bbwJXSHpjWt9USScPt6L03OXAVyW9SdI4FRcMTAD+lOL36eTUvn/6UHjaMPtmI+TQz888YL2kl4ArgTMj4uU0PHMp8E/p7fUciv+g36b4HOBpirO0XwOIiPVpehXFGfBLFGO3rwyx7c8DvwT8kCI4bmhkR9IVJf9tiEXeTXFWWvk4CTiT4sx6K8U7ngnDbS8ingVOB36fYihrFtDLT/b5dopLKrdKenak+xMRTwAfA/6A4qz4Q8CHIuLVGp6+D/BZin3aAfx30otqRHyXYh9XpWG1R4BTaiyr2j5dSPHB8D1pfX9P8XlPLT4PPAzcl+q8HNgnIjZSfOB8McUJyEbgN9N+DbpvNnIqhiXNGpPeCeykGLp5ut31tIKkfSjG9M+OiDvaXY9ZLXymb3WT9CFJB6a33V+mOIPb0N6qRlcafpiYhiQGPpO4p81lmdXMoW+NmE/xlvvfgZkUQ0V7+1vH4ymuPhkYflkQES+3tySz2nl4x8wsIz7TNzPLSEffBGvy5MnR3d3d7jLMzMaUdevWPRsRXdX6Ojr0u7u76e3tbXcZZmZjiqRnBuvz8I6ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUY6+hu5Zp2se8nNNS234bLTRrkSs9r5TN/MLCMOfTOzjAwb+pKWS9ou6ZEqfZ+TFJImp3lJ+rqkPkkPSTqutOxCSU+mx8Lm7oaZmdWiljP9FRR/THsPkqZT/IHpH5SaT6H4C0ozgcXAVWnZw4ClwLuA2cBSSZMaKdzMzEZu2NCPiLso/gJ9pSuALwDlP701H7g2CvcAEyUdAZwMrI2IHRHxPLCWKi8kZmY2uuoa05c0H9gcEQ9WdE0FNpbmN6W2wdqrrXuxpF5Jvf39/fWUZ2Zmgxhx6Es6ELgY+J3mlwMRsSwieiKip6ur6h9+MTOzOtVzpn80MAN4UNIGYBpwv6SfAjYD00vLTkttg7WbmVkLjTj0I+LhiHhjRHRHRDfFUM1xEbEVWAOck67imQO8EBFbgFuBkyRNSh/gnpTazMyshWq5ZPN64G7gGEmbJC0aYvFbgKeAPuCbwKcAImIH8CXgvvT4YmozM7MWGvY2DBFx1jD93aXpAM4fZLnlwPIR1mdmZk3kb+SamWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRmr5w+jLJW2X9Eip7f9JelzSQ5K+K2liqe8iSX2SnpB0cql9Xmrrk7Sk+btiZmbDqeVMfwUwr6JtLfC2iPg54F+BiwAkzQLOBI5Nz/kjSeMkjQO+AZwCzALOSsuamVkLDRv6EXEXsKOi7e8iYneavQeYlqbnA6si4pWIeBroA2anR19EPBURrwKr0rJmZtZCzRjT/wTwN2l6KrCx1LcptQ3WbmZmLdRQ6Ev638Bu4LrmlAOSFkvqldTb39/frNWamRkNhL6kc4EPAmdHRKTmzcD00mLTUttg7a8TEcsioicierq6uuotz8zMqqgr9CXNA74AfDgidpW61gBnSpogaQYwE/hn4D5gpqQZkvaj+LB3TWOlm5nZSI0fbgFJ1wNzgcmSNgFLKa7WmQCslQRwT0R8MiLWS1oNPEox7HN+RPxnWs+ngVuBccDyiFg/CvtjZmZDGDb0I+KsKs3XDLH8pcClVdpvAW4ZUXVmZtZU/kaumVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkWFDX9JySdslPVJqO0zSWklPpp+TUrskfV1Sn6SHJB1Xes7CtPyTkhaOzu6YmdlQajnTXwHMq2hbAtwWETOB29I8wCnAzPRYDFwFxYsEsBR4FzAbWDrwQmFmZq0zbOhHxF3Ajorm+cDKNL0SWFBqvzYK9wATJR0BnAysjYgdEfE8sJbXv5CYmdkoq3dMf0pEbEnTW4EpaXoqsLG03KbUNlj760haLKlXUm9/f3+d5ZmZWTXjG11BRISkaEYxaX3LgGUAPT09TVuv2d6ie8nNNS234bLTRrkSG4vqPdPfloZtSD+3p/bNwPTSctNS22DtZmbWQvWG/hpg4AqchcBNpfZz0lU8c4AX0jDQrcBJkialD3BPSm1mZtZCww7vSLoemAtMlrSJ4iqcy4DVkhYBzwBnpMVvAU4F+oBdwHkAEbFD0peA+9JyX4yIyg+HzcxslA0b+hFx1iBdJ1ZZNoDzB1nPcmD5iKozM7Om8jdyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy0vBdNs2sOWq9e6ZZI3ymb2aWEYe+mVlGPLyTKf8hjr3fSIaL/O+cD5/pm5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYaCn1JvyFpvaRHJF0vaX9JMyTdK6lP0g2S9kvLTkjzfam/uxk7YGZmtav7y1mSpgK/DsyKiJclrQbOBE4FroiIVZKuBhYBV6Wfz0fET0s6E7gc+GjDe2DW4XxPHeskjQ7vjAcOkDQeOBDYArwPuDH1rwQWpOn5aZ7Uf6IkNbh9MzMbgbpDPyI2A18GfkAR9i8A64CdEbE7LbYJmJqmpwIb03N3p+UPr1yvpMWSeiX19vf311uemZlVUXfoS5pEcfY+A3gTcBAwr9GCImJZRPRERE9XV1ejqzMzs5JGhnfeDzwdEf0R8R/Ad4D3ABPTcA/ANGBzmt4MTAdI/YcCzzWwfTMzG6FGQv8HwBxJB6ax+ROBR4E7gI+kZRYCN6XpNWme1H97REQD2zczsxGq++qdiLhX0o3A/cBu4F+AZcDNwCpJv5farklPuQb4tqQ+YAfFlT5m1gF8q+18NHQ//YhYCiytaH4KmF1l2R8DpzeyPTMza4y/kWtmlhGHvplZRvznEs2s6fwZQefymb6ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUZ8l00zq1mtd8+0zuUzfTOzjDj0zcwy4tA3M8tIQ2P6kiYC3wLeBgTwCeAJ4AagG9gAnBERz0sScCVwKrALODci7m9k+2YjGWOu9a80edza9maNnulfCfxtRLwVeDvwGLAEuC0iZgK3pXmAU4CZ6bEYuKrBbZuZ2QjVHfqSDgXeC1wDEBGvRsROYD6wMi22EliQpucD10bhHmCipCPqrtzMzEaskeGdGUA/8CeS3g6sAy4ApkTElrTMVmBKmp4KbCw9f1Nq21JqQ9JiincCHHnkkQ2UZ7YnD9uYNTa8Mx44DrgqIt4J/IifDOUAEBFBMdZfs4hYFhE9EdHT1dXVQHlmZlapkdDfBGyKiHvT/I0ULwLbBoZt0s/tqX8zML30/GmpzczMWqTu0I+IrcBGScekphOBR4E1wMLUthC4KU2vAc5RYQ7wQmkYyMzMWqDR2zD8GnCdpP2Ap4DzKF5IVktaBDwDnJGWvYXics0+iks2z2tw22ZmNkINhX5EPAD0VOk6scqyAZzfyPbMzKwx/kaumVlGHPpmZhlx6JuZZcT307eO5C9SmY0On+mbmWXEoW9mlhEP71hT1DocU+vtjc1sdPhM38wsIw59M7OMeHjHhtTsq2h8VY5Ze/lM38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4i/nDUGjOQLTb63jZkNpeHQlzQO6AU2R8QHJc0AVgGHA+uAj0fEq5ImANcCPw88B3w0IjY0un3bk7/xamZDacbwzgXAY6X5y4ErIuKngeeBRal9EfB8ar8iLWdmZi3UUOhLmgacBnwrzQt4H3BjWmQlsCBNz0/zpP4T0/JmZtYijZ7pfw34AvBamj8c2BkRu9P8JmBqmp4KbARI/S+k5fcgabGkXkm9/f39DZZnZmZldYe+pA8C2yNiXRPrISKWRURPRPR0dXU1c9VmZtlr5IPc9wAflnQqsD/wBuBKYKKk8elsfhqwOS2/GZgObJI0HjiU4gNdMzNrkbpDPyIuAi4CkDQX+HxEnC3pz4GPUFzBsxC4KT1lTZq/O/XfHhFRf+ljn6+0MbNWG40vZ10IfFZSH8WY/TWp/Rrg8NT+WWDJKGzbzMyG0JQvZ0XEncCdafopYHaVZX4MnN6M7ZmZWX18GwYzs4w49M3MMuLQNzPLyF59w7Var47xTcrMLBd7dei3iy/FNLNO5eEdM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLiSzZHwJdimtlY5zN9M7OMOPTNzDLi0Dczy4jH9PFYvZnlw2f6ZmYZceibmWXEoW9mlhGHvplZRuoOfUnTJd0h6VFJ6yVdkNoPk7RW0pPp56TULklfl9Qn6SFJxzVrJ8zMrDaNnOnvBj4XEbOAOcD5kmYBS4DbImImcFuaBzgFmJkei4GrGti2mZnVoe7Qj4gtEXF/mv4h8BgwFZgPrEyLrQQWpOn5wLVRuAeYKOmIuis3M7MRa8qYvqRu4J3AvcCUiNiSurYCU9L0VGBj6WmbUlvluhZL6pXU29/f34zyzMwsaTj0JR0M/AXwmYh4sdwXEQHESNYXEcsioicierq6uhotz8zMShoKfUn7UgT+dRHxndS8bWDYJv3cnto3A9NLT5+W2szMrEUauXpHwDXAYxHx1VLXGmBhml4I3FRqPyddxTMHeKE0DGRmZi3QyL133gN8HHhY0gOp7WLgMmC1pEXAM8AZqe8W4FSgD9gFnNfAts3MrA51h35EfA/QIN0nVlk+gPPr3Z6ZmTXO38g1M8uIQ9/MLCO+n76ZtU2tf8tiw2WnjXIl+fCZvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhF/OcvMOp6/xNU8PtM3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjPg6fTPba/h6/uG1/Exf0jxJT0jqk7Sk1ds3M8tZS0Nf0jjgG8ApwCzgLEmzWlmDmVnOWj28Mxvoi4inACStAuYDj7a4DjPLWK3DQLD3DQW1OvSnAhtL85uAd5UXkLQYWJxmX5L0xCDrmgw82/QKR89Yqxdcc6u45tFXd726vMmV1K6RY3zUYB0d90FuRCwDlg23nKTeiOhpQUlNMdbqBdfcKq559I21emH0am71B7mbgeml+WmpzczMWqDVoX8fMFPSDEn7AWcCa1pcg5lZtlo6vBMRuyV9GrgVGAcsj4j1da5u2CGgDjPW6gXX3CquefSNtXphlGpWRIzGes3MrAP5NgxmZhlx6JuZZWTMhf5YvI2DpA2SHpb0gKTedtdTjaTlkrZLeqTUdpiktZKeTD8ntbPGSoPUfImkzelYPyDp1HbWWCZpuqQ7JD0qab2kC1J7xx7nIWru5OO8v6R/lvRgqvl3U/sMSfem7LghXUzSdkPUu0LS06Vj/I6mbDAixsyD4sPffwPeDOwHPAjManddNdS9AZjc7jqGqfG9wHHAI6W23weWpOklwOXtrrOGmi8BPt/u2gap9wjguDR9CPCvFLcj6djjPETNnXycBRycpvcF7gXmAKuBM1P71cCvtrvWYepdAXyk2dsba2f6/3Ubh4h4FRi4jYM1KCLuAnZUNM8HVqbplcCClhY1jEFq7lgRsSUi7k/TPwQeo/iWesce5yFq7lhReCnN7pseAbwPuDG1d8xxHqLeUTHWQr/abRw6+hcwCeDvJK1Lt5kYK6ZExJY0vRWY0s5iRuDTkh5Kwz8dM1RSJqkbeCfFWd2YOM4VNUMHH2dJ4yQ9AGwH1lKMEOyMiN1pkY7Kjsp6I2LgGF+ajvEVkiY0Y1tjLfTHqhMi4jiKu4ueL+m97S5opKJ47zkWru+9CjgaeAewBfhKe8t5PUkHA38BfCYiXiz3depxrlJzRx/niPjPiHgHxbf+ZwNvbXNJQ6qsV9LbgIso6v4F4DDgwmZsa6yF/pi8jUNEbE4/twPfpfglHAu2SToCIP3c3uZ6hhUR29J/oNeAb9Jhx1rSvhTheV1EfCc1d/RxrlZzpx/nARGxE7gDOB6YKGngC6kdmR2leuelobWIiFeAP6FJx3ishf6Yu42DpIMkHTIwDZwEPDL0szrGGmBhml4I3NTGWmoyEJ7JL9JBx1qSgGuAxyLiq6Wujj3Og9Xc4ce5S9LENH0A8AGKzyLuAD6SFuuY4zxIvY+XTgRE8flDU47xmPtGbro07Gv85DYOl7a5pCFJejPF2T0Ut734s06sWdL1wFyK27luA5YCf0lxxcORwDPAGRHRMR+cDlLzXIohh6C4aupXSuPlbSXpBOAfgYeB11LzxRRj5B15nIeo+Sw69zj/HMUHteMoTmxXR8QX0//FVRRDJf8CfCydRbfVEPXeDnRRXN3zAPDJ0ge+9W9vrIW+mZnVb6wN75iZWQMc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5ll5P8DqCuo0QjIpbAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0bMmY6M0-Zs"
      },
      "source": [
        "# define maximum length of a text\n",
        "max_len = 25"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbV1OazzSnr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "c85823ef777f4a718f4cddc1a5a1b9a3",
            "c0ea21f709854dd79e0117b6e5ccf922",
            "d763853e36dd4792b44360d6d7a09a2c",
            "7d59edeb6f91414a990953897c9d048f",
            "a9e5257d589748fbbc90e1cc4d81de2b",
            "6ed666f6ed6f4b34ab44da7f73e90147",
            "b7e5dc5ea1ae42ebbf335590901eba13",
            "58df6e42c27541e4bfc873e01a8a0d93"
          ]
        },
        "outputId": "99e3aff0-882a-4572-afc3-a06c46ea9141"
      },
      "source": [
        "# library for progress bar\n",
        "from tqdm import notebook\n",
        "\n",
        "# create an empty list to save integer sequence\n",
        "sent_id = []\n",
        "\n",
        "# iterate over each tweet\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "  \n",
        "  encoded_sent = tokenizer.encode(text[i],                      \n",
        "                                  add_special_tokens = True,    \n",
        "                                  max_length = max_len,\n",
        "                                  truncation = True,         \n",
        "                                  pad_to_max_length='right')    \n",
        "  \n",
        "  # saving integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c85823ef777f4a718f4cddc1a5a1b9a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14640.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgp93PgwLg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41883f69-662e-40b9-faeb-49d3f49cc606"
      },
      "source": [
        "print(\"Integer Sequence:\",sent_id[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Integer Sequence: [101, 2054, 2056, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k73WKt0NxpeC"
      },
      "source": [
        "# create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# for each sentence...\n",
        "for sent in sent_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sent]\n",
        "  \n",
        "  # store the attention mask for this sentence.\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONLj9J9AXQN"
      },
      "source": [
        "##3.4 Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqg2GTsqxpuW"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y42CmxNaAsbZ"
      },
      "source": [
        "##3.5 Define Dataloaders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033DKuEizSuP"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPnDd5SCzWS6"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "#Dataset wrapping tensors.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "#define a sampler for sampling the data during training\n",
        "  #random sampler samples randomly from a dataset \n",
        "  #sequential sampler samples sequentially, always in the same order\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "#represents a iterator over a dataset. Supports batching, customized data loading order\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "#Dataset wrapping tensors.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "#define a sequential sampler \n",
        "#This samples data in a sequential order\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "\n",
        "#create a iterator over the dataset\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFO9vX1WD5-"
      },
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "sent_id, mask, target=iterator.next()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek5ie3hqF7Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa62d145-8890-4439-8b1c-bc2afc244fc5"
      },
      "source": [
        "sent_id.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELWRXJV0F1vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96515dc7-58c1-4e5b-d8d5-0f655a390ad5"
      },
      "source": [
        "sent_id"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2356,  3462, 16742,  2054,  5171,  9430,  2052,  2022,  1004,\n",
              "         23713,  1025,  2758,  2057,  2453,  2131,  2489,  2694,  1012,  1001,\n",
              "         21873,   102,     0,     0,     0],\n",
              "        [  101,  2003,  1996,  2995, 16558,  5657,  2609,  3714,  2012,  1996,\n",
              "          2617,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2058,  2019,  3178,  2006,  1996,  3042,  1996,  2190,  2017,\n",
              "          2064,  2425,  2033,  2003,  2009,  2001,  2741,  2672,  2026,  2924,\n",
              "         28616, 22829,  2009,  1012,   102],\n",
              "        [  101,  2079,  2017,  2031,  2151,  9735,  2000,  1996,  5865,  2265,\n",
              "          1029,  1045,  2052,  2293,  2000,  2175,  2007,  2026,  2905,   100,\n",
              "           102,     0,     0,     0,     0],\n",
              "        [  101,  4067,  2017,   102,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101, 20228,  2015,  2425,  2033,  2129,  2000,  2131,  1037,  2711,\n",
              "          2006,  1996,  3042, 17306,  2361,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2307,  4067,  2017,  1010, 11082,  3246,  2061,   999,  2071,\n",
              "          2017,  3531,  2025,  8757,  2033,  2065,  3462, 11816,  2475,  3727,\n",
              "          1046, 24316,  1029,  4067,   102],\n",
              "        [  101,  4283,  2005,  6016,  2026,  4845,  2000,  1996,  1001,  7688,\n",
              "          7265,  7446,  2015,  4164,  7136,  2061, 12476,   999,   102,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2009,  1005,  1055,  2471,  2066,  2057,  1005,  2128, 14248,\n",
              "          2005,  2542,  2379,  1037,  2312,  6005,  2181,  1012,  1041, 13088,\n",
              "          2001,  2327,  4396,  2005,   102],\n",
              "        [  101,  2064,  2017,  2393,  6273,  2683,  1999,  3190,  2131,  2000,\n",
              "          1037,  4796,  1012, 12809,  2006,  1037,  9271,  3849,  2066,  1037,\n",
              "         10231,  7685,  2518,  2000,   102],\n",
              "        [  101,  1012,  2205,  2172, 18558,  2000,  3745,  3081,  1056, 28394,\n",
              "          2102,  1012,  3531,  4604,  2033,  2115,  2171,  1998,  3967, 18558,\n",
              "          1012,  3407,  2000,  4425,   102],\n",
              "        [  101,  2525,  2985,  3438,  8117,  2015,  2651,  8304,  2023,  2005,\n",
              "          2026,  3576,  2775,  1012,  9467,  2006,  2017,  2005, 12318,  1037,\n",
              "          2321,  2095,  2214,  2611,   102],\n",
              "        [  101,  2044,  2256,  4895, 22842,  8566,  3709, 23026,  2644,  1998,\n",
              "          4394,  1016,  7176,  7599,  2057,  1054,  2188,  1050,  2559,  1018,\n",
              "          7652,  2000,  2256,  2793,   102],\n",
              "        [  101,  2145,  3403,   999,  2952,  4311,  2002,  1005,  1055,  2170,\n",
              "          1020,  2335,  2000,  2131,  2598,  3626,  1012,  1012,  1012,  1012,\n",
              "          1998,  2145,  3564,  2006,   102],\n",
              "        [  101,  1011,  2459,  8737,  2232,  7266,  1998,  2052,  2079,  2505,\n",
              "          2000,  2022,  1999,  3516,  2157,  2085,  1012,  1012,  2393,  1037,\n",
              "          2905,  2041,   999,   999,   102],\n",
              "        [  101, 16215,  2595,  1012,  2191,  2009,  2157,  1012,  2393,  2033,\n",
              "         16098,  2078,  1042,  5833,  2100, 24905, 11266,  2080, 13109,  1001,\n",
              "         25578,  2487,  1040,  2546,   102],\n",
              "        [  101,  2057,  3745,  2008,  3643,  1999,  2691,  1012,  1024,  1007,\n",
              "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  7632,   999,  1045,  2074,  2387,  1037,  2304,  2381,  3204,\n",
              "          3293,  2006,  2694,  1004, 23713,  1025, 10047,  7568,   999,  1999,\n",
              "          2490,  1997,  2023,  3204,   102],\n",
              "        [  101,  4067,  2017,  1010,  2021,  2009,  2758,  1996,  4037,  2003,\n",
              "          2091,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  2038,  1996,  5409,  3462, 26727,  1012,  2027,  2024,  2066,\n",
              "          2216,  4854,  1998,  7144,  5916,  2015,  2008,  2057,  2035,  2031,\n",
              "          1012,  2673,  2038,  2000,   102],\n",
              "        [  101,  2393,   999,  2009,  2758,  1000,  1996,  7909,  2003,  6380,\n",
              "          1000,  2021,  2026,  2769,  2038,  2042,  2579,  2041,  1997,  2026,\n",
              "          2924,  1029,  1998,  2009,   102],\n",
              "        [  101,  1045,  2572,  2200,  9364,  2007,  2004,  2115,  4256,  1012,\n",
              "          2053,  4807,  1010,  1016,  5186,  2397,  3462,  7599,  1012,  2428,\n",
              "          1010,  2035,  2105,  9202,   102],\n",
              "        [  101,  1001,  5409,  2475, 19496,  3064, 28968,  3366,  6299, 25423,\n",
              "         23593,  5869,  2000, 24264,  2094,  1016,  1013,  2484,  6228,  3471,\n",
              "          2153,  1011,  2165,  2125,   102],\n",
              "        [  101,  2003,  2115,  2194, 12652,  1024,  1000,  1045,  2079,  2025,\n",
              "          2729,   999,   999,   999,  1000,  1045,  2657,  2195,  2335,  2013,\n",
              "          2115,  5126,  2000,  2115,   102],\n",
              "        [  101,  2643,  4365,  8239,  3626,  2180,  1005,  1056,  2022,  2182,\n",
              "          6229,  1020,  1024,  2871,  1010,  2061,  2017,  1005,  2310,  2124,\n",
              "          2005,  2058,  2019,  3178,   102],\n",
              "        [  101,  2006,  3462, 28460,  2000,  5395,  8394,  2349,  6593,  2080,\n",
              "          3194,  4390,  1012,  2097,  2140,  2017,  2907,  2026,  4434,  2000,\n",
              "          5619,  2012,  5395,  2144,   102],\n",
              "        [  101,  5760, 26395,  2006,  3462, 29541,  2000, 22889,  2278,  1012,\n",
              "          2111,  3788,  1999,  2007,  2498,  8966,  1999,  8641,  2007,  2608,\n",
              "          2440,  1997,  4933,  1012,   102],\n",
              "        [  101,  4931,  2144,  2017,  1042,  1008,  1003,  1001,  3968,  2026,\n",
              "          1059,  2243,  4859,  2064,  1045,  2031,  2154,  3413,  2000,  5902,\n",
              "          2015,  2252,  2030,  7954,   102],\n",
              "        [  101,  1045,  2001,  2761,  2667,  2000,  3745,  4751,  2021,  1996,\n",
              "          4957,  5261,  3520,  8445,  5831,  2015,  3580,  2343,  1011,  8013,\n",
              "          3325,  2741,  2033, 13735,   102],\n",
              "        [  101, 14541,  2039,  2026,  7599, 17718, 21531,  4244,  1996,  3976,\n",
              "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101, 25430,  2050,  2003,  5627,  2000,  3582,  2039,  1012,  2633,\n",
              "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0],\n",
              "        [  101,  8295,  1996,  2489,  1001, 15536,  8873,  1998,  1001,  4190,\n",
              "          9954,   100,  1001,  5862, 15494,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ88suqBjeuo"
      },
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id,             #integer sequence\n",
        "               attention_mask=mask) #attention masks"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleBnOAn5V7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bfefeb-7909-4993-a0ed-b6a3324786a8"
      },
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Hidden States: torch.Size([32, 25, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb189wFSR0cE"
      },
      "source": [
        "#4. Model Finetuning \n",
        "\n",
        "*The pretrained model is trained on the general domain corpus. So, finetuning the pretrained model helps in the capturing the domain specific features from our custom dataset*\n",
        "\n",
        "\n",
        "Every pretrained model is trained using 2 different layers : **BackBone and Head** \n",
        "\n",
        "* Backbone refers to the pretrained model architecture \n",
        "* Head refers to the dense layer added on top of backbone. Generally, this layer is used for the classification tasks.\n",
        "\n",
        "Hence, we can finetune the pretrained model in 2 ways\n",
        "\n",
        "**1. Fine-Tuning only Head (or Dense Layer)**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states\n",
        "\n",
        "\n",
        "**2. Fine-Tuning both Backbone & Head**\n",
        "\n",
        "1.1  CLS token\n",
        "\n",
        "1.2  Hidden states \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml6av5LqA24e"
      },
      "source": [
        "### 4.1 Approach: Fine-Tuning Only Head\n",
        "\n",
        "As the name suggests, in this approach, we freeze the backbone and train only the head or dense layer.\n",
        "\n",
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients\n",
        "\n",
        "2. Define Model Architecture\n",
        "\n",
        "3. Define Optimizer and Loss\n",
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "5. Train the model\n",
        "\n",
        "6. Evaluate the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDpxm52C5mpe"
      },
      "source": [
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kF7mh9TM_Rl"
      },
      "source": [
        "##4.2 Define Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RIDAa4NF5m5"
      },
      "source": [
        "#importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert \n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "      \n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask , return_dict = False)\n",
        "      \n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6z3HDPF5lA"
      },
      "source": [
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "model = model.to(device)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9R5XajGF5jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16397a4c-56d1-4bd3-df94-bf259e47e0af"
      },
      "source": [
        "#model architecture \n",
        "model"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fxTyKbRUGC5"
      },
      "source": [
        "# push the tensors to GPU\n",
        "sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLwIPXWNWg4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403f9a3c-6da1-4735-84d4-f9b48f5ac194"
      },
      "source": [
        "# understand outputs\n",
        "print(outputs)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2128, -0.9313, -1.1757],\n",
            "        [-1.1365, -1.0099, -1.1558],\n",
            "        [-1.3063, -0.9194, -1.1074],\n",
            "        [-1.3121, -0.9173, -1.1052],\n",
            "        [-1.2669, -0.9751, -1.0755],\n",
            "        [-1.2334, -0.9845, -1.0934],\n",
            "        [-1.3703, -0.9488, -1.0251],\n",
            "        [-1.2537, -0.9272, -1.1429],\n",
            "        [-1.3109, -0.9730, -1.0428],\n",
            "        [-1.2737, -0.9752, -1.0698],\n",
            "        [-1.2786, -0.9544, -1.0891],\n",
            "        [-1.2787, -0.9645, -1.0775],\n",
            "        [-1.3131, -0.9617, -1.0533],\n",
            "        [-1.2409, -1.0115, -1.0578],\n",
            "        [-1.1876, -1.0381, -1.0761],\n",
            "        [-1.2625, -0.9897, -1.0632],\n",
            "        [-1.2373, -1.0022, -1.0707],\n",
            "        [-1.2461, -0.9945, -1.0716],\n",
            "        [-1.3325, -0.9382, -1.0646],\n",
            "        [-1.2845, -0.9313, -1.1112],\n",
            "        [-1.1765, -1.0648, -1.0589],\n",
            "        [-1.2154, -1.0273, -1.0630],\n",
            "        [-1.3154, -0.9698, -1.0428],\n",
            "        [-1.2235, -0.9978, -1.0874],\n",
            "        [-1.3029, -0.9599, -1.0632],\n",
            "        [-1.2275, -0.9926, -1.0896],\n",
            "        [-1.2722, -0.9311, -1.1218],\n",
            "        [-1.2132, -0.9932, -1.1016],\n",
            "        [-1.2384, -0.9659, -1.1102],\n",
            "        [-1.2261, -1.0211, -1.0602],\n",
            "        [-1.1968, -1.0132, -1.0943],\n",
            "        [-1.2288, -0.9536, -1.1332]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJoc1aGYN1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db35c7ab-bc16-4415-884b-c2864e173066"
      },
      "source": [
        "# no. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTdl4RZNHk4"
      },
      "source": [
        "## 4.3 Define Optimizer and Loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7fjPGyQaVw"
      },
      "source": [
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Op_QSrUvem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "e90be321-1900-4710-8b88-a8686ba1c1b6"
      },
      "source": [
        "# understand the class distribution\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bat chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpluCEUzijp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566381a1-7fa4-4771-e31e-bf6c6a38bd49"
      },
      "source": [
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(labels), labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Weights: [0.53170625 1.57470152 2.06517139]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJuWGiqF5eM"
      },
      "source": [
        "# converting a list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqtirPVDg8aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42283b5c-2a9a-4c1b-ef25-f2946cfda3ea"
      },
      "source": [
        "#compute the loss\n",
        "loss = cross_entropy(outputs, target)\n",
        "print(\"Loss:\",loss)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: tensor(1.1155, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-Sx2rgyu4Aj"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJixsg1XzHCA"
      },
      "source": [
        "## 4.4 Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFPILeF9Spxe"
      },
      "source": [
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches.\n",
        "\n",
        "During training, for each batch, we need to\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropagate Loss\n",
        "4. Update Weights \n",
        "\n",
        "Where as during evaluation, for each batch, we need to\n",
        "\n",
        "1. Perform forward pass\n",
        "2. Compute loss\n",
        "\n",
        "```\n",
        "Training: Epoch -> Batch -> Forward Pass -> Compute loss -> Backpropagate loss -> Update weights \n",
        "```\n",
        "\n",
        "```\n",
        "Evaluation: Epoch -> Batch -> Forward Pass -> Compute loss\n",
        "```\n",
        "\n",
        "Hence, for each epoch, we have a training phase and a validation phase. After each batch we need to:\n",
        "\n",
        "**Training phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Clear out the gradients calculated in the previous pass.\n",
        "\n",
        "4. Forward pass (feed input data through the network)\n",
        "\n",
        "5. Backward pass (backpropagation)\n",
        "\n",
        "6. Update parameters with optimizer.step()\n",
        "\n",
        "7. Track variables for monitoring progress\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgIYKxjv2Wv0"
      },
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "  \n",
        "  print(\"\\nTraining.....\")  \n",
        "  \n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically. \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels)\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value \n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "  \n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SF3wrDuSwpj"
      },
      "source": [
        "\n",
        "**Evaluation phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "\n",
        "2. Unpack our data inputs and labels\n",
        "\n",
        "3. Forward pass (feed input data through the network)\n",
        "\n",
        "4. Compute loss on our validation data\n",
        "\n",
        "5. Track variables for monitoring progress\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPKfeGlC5_WE"
      },
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.      \n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7d_XacvNgyU"
      },
      "source": [
        "##4.5 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_sj66daFTAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8d021e-dae0-46d3-ea55-e084cbbd9615"
      },
      "source": [
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "....... epoch 1 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.755\n",
            "Validation Loss: 0.696\n",
            "\n",
            "....... epoch 2 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.742\n",
            "Validation Loss: 0.789\n",
            "\n",
            "....... epoch 3 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.754\n",
            "Validation Loss: 0.667\n",
            "\n",
            "....... epoch 4 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.730\n",
            "Validation Loss: 0.639\n",
            "\n",
            "....... epoch 5 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.738\n",
            "Validation Loss: 0.719\n",
            "\n",
            "....... epoch 6 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.732\n",
            "Validation Loss: 0.668\n",
            "\n",
            "....... epoch 7 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.722\n",
            "Validation Loss: 0.640\n",
            "\n",
            "....... epoch 8 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.723\n",
            "Validation Loss: 0.654\n",
            "\n",
            "....... epoch 9 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.724\n",
            "Validation Loss: 0.726\n",
            "\n",
            "....... epoch 10 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.722\n",
            "Validation Loss: 0.627\n",
            "\n",
            "....... epoch 11 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.722\n",
            "Validation Loss: 0.657\n",
            "\n",
            "....... epoch 12 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.712\n",
            "Validation Loss: 0.627\n",
            "\n",
            "....... epoch 13 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.709\n",
            "Validation Loss: 0.669\n",
            "\n",
            "....... epoch 14 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.713\n",
            "Validation Loss: 0.623\n",
            "\n",
            "....... epoch 15 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.708\n",
            "Validation Loss: 0.630\n",
            "\n",
            "....... epoch 16 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.709\n",
            "Validation Loss: 0.623\n",
            "\n",
            "....... epoch 17 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.712\n",
            "Validation Loss: 0.622\n",
            "\n",
            "....... epoch 18 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.705\n",
            "Validation Loss: 0.614\n",
            "\n",
            "....... epoch 19 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.709\n",
            "Validation Loss: 0.623\n",
            "\n",
            "....... epoch 20 / 20 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    412.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    412.    Elapsed: 0:00:04.\n",
            "  Batch   120  of    412.    Elapsed: 0:00:06.\n",
            "  Batch   160  of    412.    Elapsed: 0:00:08.\n",
            "  Batch   200  of    412.    Elapsed: 0:00:10.\n",
            "  Batch   240  of    412.    Elapsed: 0:00:12.\n",
            "  Batch   280  of    412.    Elapsed: 0:00:14.\n",
            "  Batch   320  of    412.    Elapsed: 0:00:16.\n",
            "  Batch   360  of    412.    Elapsed: 0:00:18.\n",
            "  Batch   400  of    412.    Elapsed: 0:00:20.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "\n",
            "Training Loss: 0.698\n",
            "Validation Loss: 0.691\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNhFJ0DANldu"
      },
      "source": [
        "##4.6 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4OPuAKj6Kiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb19ef3d-a3ff-447d-9e97-1b42ac59375f"
      },
      "source": [
        "# load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqwKsGeFTDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40630e50-87f8-4438-ab7e-cb364253cb7a"
      },
      "source": [
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     46.    Elapsed: 0:00:02.\n",
            "0.6139633305694746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DehF35geFTIB"
      },
      "source": [
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "y_pred = np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true = validation_labels"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXjiXdk5Co8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb4599b-f617-42b6-e83a-03da84710962"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.75      0.82       918\n",
            "           1       0.52      0.68      0.59       310\n",
            "           2       0.64      0.81      0.72       236\n",
            "\n",
            "    accuracy                           0.74      1464\n",
            "   macro avg       0.69      0.75      0.71      1464\n",
            "weighted avg       0.78      0.74      0.75      1464\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7ThrTqbYo8U"
      },
      "source": [
        "# We have achieved 74% accuracy we can further improve it Finetuning some other bert model"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeWJy_fPmBdq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}